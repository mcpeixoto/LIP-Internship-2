{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('env_tensorflow': venv)"
  },
  "interpreter": {
   "hash": "7cfbf909c009492aafe796b3bfb5ce0117a930ec56b9e9020f69c22f95d83cb1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reparametrize(keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        mean, log_var = inputs\n",
    "        return K.random_normal(tf.shape(log_var)) * K.exp(log_var / 2) + mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 2\n",
    "\n",
    "## Encoder\n",
    "inputs = keras.layers.Input(shape=[69])\n",
    "z = keras.layers.Dense(128)(inputs)\n",
    "z = keras.layers.LeakyReLU()(z)\n",
    "\n",
    "mean = keras.layers.Dense(hidden_size)(z)\n",
    "log_var = keras.layers.Dense(hidden_size)(z)\n",
    "latent = Reparametrize()([mean, log_var])\n",
    "\n",
    "encoder = keras.Model(inputs=[inputs], outputs=[mean, log_var, latent])\n",
    "\n",
    "## Decoder \n",
    "decoder_inputs = keras.layers.Input(shape=[hidden_size])\n",
    "z = keras.layers.Dense(128)(decoder_inputs)\n",
    "z = keras.layers.LeakyReLU()(z)\n",
    "z = keras.layers.Dense(69)(decoder_inputs)\n",
    "outputs = keras.layers.LeakyReLU()(z)\n",
    "\n",
    "decoder = keras.Model(inputs=[decoder_inputs], outputs=[outputs])\n",
    "\n",
    "## Joining everything\n",
    "_, _, latent = encoder(inputs)\n",
    "reconstruction = decoder(latent)\n",
    "model = keras.Model(inputs=[inputs], outputs=[reconstruction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss\n",
    "latent_loss = -0.5 * K.sum(1 + log_var - -K.exp(log_var) - K.square(mean), axis=-1)\n",
    "model.add_loss(K.mean(latent_loss)/69)\n",
    "\n",
    "## Compile\n",
    "# The model will calculate the reconstruction loss with binary_crossentropy and then sum the KL loss to it\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"adam\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}