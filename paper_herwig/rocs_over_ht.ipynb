{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import random\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import Adam\n",
    "from pytorch_lightning import Trainer\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "from typing import Optional\n",
    "from config import processed_data_path\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.notebook import tqdm\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from scipy.stats import wasserstein_distance \n",
    "import joblib\n",
    "import optuna\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import wasserstein_distance\n",
    "import threading\n",
    "import concurrent\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# For saving img\n",
    "from os.path import join, basename, exists\n",
    "from os import getcwd\n",
    "dir_name = basename(getcwd())\n",
    "img_dir = join(getcwd(), \"images\")\n",
    "if not exists(img_dir):\n",
    "    os.mkdir(img_dir)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# For saving ROC Values\n",
    "currect_dir = getcwd()\n",
    "os.chdir(\"..\")\n",
    "base_directory = getcwd()\n",
    "os.chdir(currect_dir) \n",
    "variante = \"ht\"\n",
    "import pickle\n",
    "\n",
    "try:\n",
    "    rocs_scores = pickle.load( open( join(base_directory, \"generate_tables\",  dir_name+\"_\"+variante+\".p\"), \"rb\" ) )\n",
    "except:\n",
    "    rocs_scores = {}\n",
    "\n",
    "pickle.dump( rocs_scores, open( join(base_directory, \"generate_tables\", dir_name+\"_\"+variante+\".p\"), \"wb\" ) )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import glob\n",
    "from config import *\n",
    "bkg_files = glob.glob(join(raw_data_path, \"bkg.*\"))\n",
    "signal_files = list(set(glob.glob(join(raw_data_path, \"*.*\"))) - set(bkg_files))\n",
    "all_files = bkg_files + signal_files\n",
    "\n",
    "print(\"Signal files:\", len(signal_files), \"\\nBackground files:\", len(bkg_files), \"\\n> Total:\", len(all_files))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from os.path import basename\n",
    "all_data = []\n",
    "\n",
    "for path in all_files:\n",
    "    data = pd.read_hdf(path, index_col=0)\n",
    "\n",
    "    data['name'] = basename(path).replace(\".h5\", \"\")\n",
    "    all_data.append(data)\n",
    "\n",
    "data = pd.concat(all_data)\n",
    "del all_data\n",
    "data = data[['name', 'ScalarHT_HT', 'gen_xsec']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.hist(data['ScalarHT_HT'], bins=50)\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "to_plot = np.log(data[data['name'] == 'bkg']['ScalarHT_HT'] + np.finfo(float).eps)\n",
    "to_plot = to_plot - to_plot.min()\n",
    "to_plot = to_plot / to_plot.max()\n",
    "plt.hist(to_plot, bins=50)\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "to_plot = np.log(data[data['name'] != 'bkg']['ScalarHT_HT'] + np.finfo(float).eps)\n",
    "to_plot = to_plot - to_plot.min()\n",
    "to_plot = to_plot / to_plot.max()\n",
    "plt.hist(to_plot, bins=50)\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import confusion_matrix,precision_score\n",
    "\n",
    "bins = 50\n",
    "\n",
    "# Plot creation\n",
    "features = list(data['name'].unique())\n",
    "\n",
    "distributions = {}\n",
    "\n",
    "for x in tqdm(features, total=len(features), desc=\"Processing...\"):\n",
    "\n",
    "    ## Get the relevant data\n",
    "    sData = data.loc[data['name'] == x].drop(columns=['name'])\n",
    "    sData = sData['ScalarHT_HT']\n",
    "    sData = sData.to_numpy(dtype=np.float32)\n",
    "\n",
    "    sData = np.log(sData + np.finfo(float).eps)\n",
    "    # Append to list\n",
    "    distributions[x] = sData"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Normalize the distributions\n",
    "# This way all values should be between 0 and 1\n",
    "\n",
    "# x transform\n",
    "min_of_dist = min(map(lambda x: min(x), distributions.values()))\n",
    "for x in distributions:\n",
    "    distributions[x] = distributions[x] - min_of_dist\n",
    "# scale\n",
    "max_of_dist = max(map(lambda x: max(x), distributions.values()))\n",
    "for x in distributions:\n",
    "    distributions[x] = distributions[x] / max_of_dist"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Plot error distributions\n",
    "fig, ax = plt.subplots( figsize=(10,10))\n",
    "ax.set_yscale('log')\n",
    "\n",
    "for x in tqdm(distributions.keys(), desc=\"Processing...\"):\n",
    "\n",
    "    hist_range = (0, 1)        \n",
    "\n",
    "    if x != 'bkg':\n",
    "        ax.hist(distributions[x], bins=bins, alpha=0.9, label=x.replace(\".h5\", \"\"), range=hist_range, histtype=u'step', linewidth=2, density=True)\n",
    "    else:\n",
    "        ax.hist(distributions[x], bins=bins, alpha=0.2, label=x.replace(\".h5\", \"\"), range=hist_range, density=True)\n",
    "\n",
    "ax.autoscale(enable=True) \n",
    "ax.set_title(\"Error Dist.\")\n",
    "ax.legend()\n",
    "fig.savefig(join(img_dir, dir_name+\"_ht_dist.png\"), bbox_inches = 'tight')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "## Plot ROC Curves\n",
    "fig_roc, ax_roc = plt.subplots(figsize=(10,10))\n",
    "for x in tqdm(distributions.keys(), desc=\"Processing...\"):\n",
    "    if x != 'bkg':\n",
    "        # Set labels\n",
    "        bkg_labels = np.zeros(distributions['bkg'].shape[0]).astype(int)\n",
    "        signal_labels = np.ones(distributions[x].shape[0]).astype(int)\n",
    "        labels = np.concatenate([bkg_labels, signal_labels])\n",
    "\n",
    "        # Set Scores\n",
    "        score = np.concatenate([distributions['bkg'], distributions[x]]) \n",
    "\n",
    "        # Set weights\n",
    "        weights = pd.concat([\n",
    "                            data[data['name'] == \"bkg\"]['gen_xsec'], \n",
    "                            data[data['name'] == x]['gen_xsec']\n",
    "                            ])\n",
    "\n",
    "        # Get Curve\n",
    "        fpr, tpr, thr = roc_curve(\n",
    "                y_true=labels, \n",
    "                y_score=score,\n",
    "                sample_weight=weights\n",
    "                )\n",
    "        \n",
    "        \n",
    "        ax_roc.plot(fpr, tpr, label=x)\n",
    "        ax_roc.plot([0,1],[0,1], 'k--')\n",
    "\n",
    "        auc_score = roc_auc_score(y_true=labels, \n",
    "                    y_score=score,\n",
    "                    sample_weight=weights)\n",
    "        namee = x.replace('.h5', '')\n",
    "\n",
    "        rocs_scores[namee] = auc_score\n",
    "        print(f\"ROC SCORE for {namee}:\", auc_score)\n",
    "        #print(score.min(), score.max())\n",
    "        #print(np.unique(np.rint(score)))\n",
    "        print(\"Confusion matrix:\")\n",
    "        print(confusion_matrix(labels, np.rint(score)))\n",
    "        print(\"\\n\")\n",
    "fig_roc.show()\n",
    "ax_roc.set_title(f\"BKG vs Signals\")\n",
    "ax_roc.legend()\n",
    "            \n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "fig_roc.savefig(join(img_dir, dir_name+\"_ht_rocs.png\"), bbox_inches = 'tight')\n",
    "# Save rocs to pickle\n",
    "pickle.dump( rocs_scores, open( join(base_directory, \"generate_tables\", dir_name+\"_\"+variante+\".p\"), \"wb\" ) )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}