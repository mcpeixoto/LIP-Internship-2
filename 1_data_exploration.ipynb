{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.3 64-bit"
  },
  "interpreter": {
   "hash": "4e1d9a8909477db77738c33245c29c7265277ef753467dede8cf3f814cde494e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from os.path import basename\n",
    "from config import bkg_data_path, signal_data_path"
   ]
  },
  {
   "source": [
    "# Sanity checks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Listing all the files on the bkg and signal directory (file path)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Signal files: 5 \nBackground files: 18 \n> Total: 23\n"
     ]
    }
   ],
   "source": [
    "bkg_files = glob.glob(join(bkg_data_path, \"*.*\"))\n",
    "signal_files = glob.glob(join(signal_data_path, \"*/*.*\"))\n",
    "all_files = bkg_files + signal_files\n",
    "\n",
    "print(\"Signal files:\", len(signal_files), \"\\nBackground files:\", len(bkg_files), \"\\n> Total:\", len(all_files))"
   ]
  },
  {
   "source": [
    "## Checking features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = {}\n",
    "for path in all_files:\n",
    "    # Load data\n",
    "    if path.endswith(\".csv\"):\n",
    "        data = pd.read_csv(path)\n",
    "    elif path.endswith(\".h5\"):\n",
    "        data = pd.read_hdf(path)\n",
    "\n",
    "    # Get features\n",
    "    features = list(data.columns)\n",
    "\n",
    "    file_name = basename(path)\n",
    "    for feature in features:\n",
    "        if feature not in book:\n",
    "            book[feature] = []\n",
    "        book[feature] += [file_name]\n",
    "\n",
    "    # Saving memory\n",
    "    del data"
   ]
  },
  {
   "source": [
    "After getting a directory with the structure:\n",
    "- {feature:\\[name_of_file\\]}\n",
    "\n",
    "We can compare each of the files features to see if they match"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nFeature \"gen_sample\" is missing on 1 file(s).\n-> Files that are missing the feature:\n\t {'tZFCNC.h5'}\n\nFeature \"gen_filter\" is missing on 1 file(s).\n-> Files that are missing the feature:\n\t {'tZFCNC.h5'}\n\nFeature \"gen_decay_filter\" is missing on 1 file(s).\n-> Files that are missing the feature:\n\t {'tZFCNC.h5'}\n\nFeature \"MissingET_Eta\" is missing on 22 file(s).\n-> Files that are missing the feature:\n\t {'WW_2L_PTW0to250.csv', 'ZZ_2L_PTZ500.csv', 'Zbb_2L_HT0to250.csv', 'Zbb_2L_HT250to500.csv', 'ZZ_2L_PTZ0to250.csv', 'Zjj_2L_HT500.csv', 'Zbb_2L_HT500.csv', 'mch45_HG_13TeV_HG3000_HQ1000_train.csv', 'ZZ_2L_PTZ250to500.csv', 'WW_2L_PTW500.csv', 'WZ_2L_PTZ500.csv', 'WW_2L_PTW250to500.csv', 'mch45_HG_13TeV_HG3000_HQ1000_test.csv', 'mch45_HG_13TeV_wohg_HQ1000_train.csv', 'WZ_2L_PTZ0to250.csv', 'mch45_HG_13TeV_wohg_HQ1000_test.csv', 'WZ_2L_PTZ250to500.csv', 'Zjj_2L_HT250to500.csv', 'ttbar_2L_PTtop0to100.csv', 'ttbar_2L_PTtop100to250.csv', 'Zjj_2L_HT0to250.csv', 'ttbar_2L_PTtop250.csv'}\n"
     ]
    }
   ],
   "source": [
    "for x in book:\n",
    "    if len(book[x]) != len(all_files):\n",
    "        print(f\"\\nFeature \\\"{x}\\\" is missing on\",  len(all_files)-len(book[x]), \"file(s).\")\n",
    "        print(\"-> Files that are missing the feature:\\n\\t\", set([basename(x) for x in all_files]) - set(book[x]))\n",
    "    #print(len(book[x]))"
   ]
  },
  {
   "source": [
    "Since the features highlighted by out little script are irrelevant, we can just mass-delete them on all the files when we pre-process the data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}