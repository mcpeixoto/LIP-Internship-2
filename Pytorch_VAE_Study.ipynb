{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import random\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.utils import save_image\n",
    "from torch.optim import Adam\n",
    "from pytorch_lightning import Trainer\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "from typing import Optional\n",
    "from config import processed_data_path\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.notebook import tqdm\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from scipy.stats import wasserstein_distance \n",
    "import joblib\n",
    "import optuna\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import wasserstein_distance\n",
    "import threading\n",
    "import concurrent\n",
    "\n",
    "from Pytorch_Optuna_Optimization import _dataset, VAE"
   ]
  },
  {
   "source": [
    "## Loading the Study"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"minimize\", study_name=\"Optimizing the VAE with r2\", storage=\"sqlite:///wd-sample_vs_data-optimization.db\", load_if_exists=True)\n",
    "#study.optimize(objective, timeout=int(7*60*60))#n_trials=200)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "print(\" TRIAL NUMBER:\", trial.number)\n"
   ]
  },
  {
   "source": [
    "### Optuna Graphs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "source": [
    "## Anomaly Detection\n",
    "\n",
    "### Load the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = VAE.load_from_checkpoint(\n",
    "    #join('models', f\"sample_vs_data_trial_{study.best_trial.number}.ckpt\"),\n",
    "    \"/mnt/D/estagio_lip_2/models/CustomTrain_WD-Data_vs_Sampling-hidden=11_max_epochs=1000.ckpt\",\n",
    "    trial = optuna.trial.FixedTrial(study.best_trial.params), \n",
    "    dataset = \"bkg\", \n",
    "    batch_size=512)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "source": [
    "### Load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bkg\n",
    "bkg, _, _ = _dataset(category='test',variant='bkg').all_data()\n",
    "bkg = bkg[:500000] # Previous size 1 266 649\n",
    "bkg.shape\n"
   ]
  },
  {
   "source": [
    "## Check if z ~ N(0,1)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, x_out, hidden = model.test_step(torch.from_numpy(bkg.to_numpy(dtype=np.float32)))\n",
    "x_out = x_out.detach().numpy()\n",
    "hidden = hidden.detach().numpy()\n",
    "hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=[25,25])\n",
    "i = 0\n",
    "\n",
    "for x in range(hidden.shape[1]):\n",
    "    axes = fig.add_subplot(7,4,i+1)\n",
    "    i += 1\n",
    "\n",
    "    axes.hist(hidden[:, x], bins='auto')\n",
    "    axes.axis(xmin=-5,xmax=5)\n",
    "    #axes.title(f\"Z{x}\")\n",
    "    print(\"Mean:\", hidden[:, x].mean(), \"\\tStd:\", hidden[:, x].std())\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "source": [
    "## Bkg Data vs Random Sampling Decoding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random sample from N(0,1)\n",
    "sample = model.decode(torch.rand(bkg.shape[0], study.best_trial.params['hidden_size'])).detach().numpy()\n",
    "\n",
    "# Make it a dataframe\n",
    "sample = pd.DataFrame(sample, columns=bkg.columns)\n",
    "sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs2(background, signal, bins=50, num_cols=4, first_name=\"Signal\", second_name=\"Sampled\"):\n",
    "    WD_SCORE = 0\n",
    "    R2_SCORE = 0\n",
    "    # Ignoring irrelevant features such as 'name' and 'weights' in\n",
    "    # the plotting of the data\n",
    "    features  = list(background.columns)\n",
    "    for x in ['name', 'weights']: \n",
    "        try:\n",
    "            features.remove(x)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Plot creation\n",
    "    num_rows = int(np.ceil((len(list(background.columns)) - 1) / num_cols)) +1\n",
    "    fig, ax = plt.subplots(num_rows, num_cols, figsize=(40, 60))\n",
    "    i= 0\n",
    "\n",
    "    for x in tqdm(features, total=len(features), desc=\"Processing...\"):\n",
    "\n",
    "        # Plot  \n",
    "        row, col = int(i/num_cols), i%num_cols\n",
    "        #print(row, col, i)\n",
    "        i += 1\n",
    "\n",
    "\n",
    "        # Define histogram range\n",
    "        hist_min = min(signal[x].min(), background[x].min())\n",
    "        hist_max = max(signal[x].max(), background[x].max())\n",
    "        hist_range = (hist_min, hist_max)\n",
    "\n",
    "\n",
    "        ax[row, col].set_title(x)\n",
    "        ax[row, col].set_yscale('log')\n",
    "        \n",
    "        ax[row, col].hist(background[x], bins=bins, alpha=0.5, label=first_name, range=hist_range)\n",
    "        ax[row, col].hist(signal[x], bins=bins, alpha=0.5, label=second_name,  range=hist_range)\n",
    "        \n",
    "        ax[row, col].autoscale(enable=True) \n",
    "        ax[row, col].legend()\n",
    "\n",
    "        WD_SCORE += wasserstein_distance(background[x], signal[x])\n",
    "        R2_SCORE += r2_score(background[x],signal[x])\n",
    "        \n",
    "\n",
    "    fig.tight_layout()\n",
    "    #plt.savefig('1_explore_data.png', bbox_inches='tight', dpi=100)\n",
    "    plt.show()\n",
    "    print(\"WD_SCORE:\", WD_SCORE/len(features))\n",
    "    print(\"R2_SCORE:\", R2_SCORE/len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs2(bkg, sample)"
   ]
  },
  {
   "source": [
    "## Bkg Data vs Reconstruction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs3(first, second, first_name=\"Signal\", second_name=\"Sampled\", bins=50, num_cols=4, num_features=69):\n",
    "\n",
    "    R2_SCORE = 0\n",
    "\n",
    "    # Reshape\n",
    "    first = first.reshape(num_features, -1)\n",
    "    second = second.reshape(num_features, -1)\n",
    "\n",
    "    # Plot creation\n",
    "    num_rows = int(np.ceil((num_features - 1) / num_cols)) +1\n",
    "    fig, ax = plt.subplots(num_rows, num_cols, figsize=(40, 60))\n",
    "    i= 0\n",
    "\n",
    "    for x in tqdm(range(num_features), total=num_features, desc=\"Processing...\"):\n",
    "\n",
    "        # Plot  \n",
    "        row, col = int(i/num_cols), i%num_cols\n",
    "        #print(row, col, i)\n",
    "        i += 1\n",
    "\n",
    "\n",
    "        # Define histogram range\n",
    "        hist_min = min(first[x].min(), second[x].min())\n",
    "        hist_max = max(first[x].max(), second[x].max())\n",
    "        hist_range = (hist_min, hist_max)\n",
    "\n",
    "\n",
    "        ax[row, col].set_title(x)\n",
    "        ax[row, col].set_yscale('log')\n",
    "        \n",
    "        ax[row, col].hist(first[x], bins=bins, alpha=0.5, label=first_name, range=hist_range)\n",
    "        ax[row, col].hist(second[x], bins=bins, alpha=0.5, label=second_name,  range=hist_range)\n",
    "\n",
    "        x = x.cpu().numpy()\n",
    "        output = output.cpu().numpy()\n",
    "\n",
    "        #print(\"Input\", np.isnan(x).any())\n",
    "        #print(\"Output\", np.isnan(output).any())\n",
    "\n",
    "\n",
    "        R2_SCORE += r2_score(first[x],second[x])\n",
    "        \n",
    "\n",
    "    fig.tight_layout()\n",
    "    #plt.savefig('1_explore_data.png', bbox_inches='tight', dpi=100)\n",
    "    plt.show()\n",
    "    print(\"R2_SCORE:\", R2_SCORE/num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs2(bkg, pd.DataFrame(x_out, columns=bkg.columns), first_name=\"Bkg\", second_name=\"Reconstruction\")"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Plot error distributions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = _dataset(category='all',variant='signal').all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal['name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal.drop(columns=['weights'], inplace=True)"
   ]
  },
  {
   "source": [
    "Plot"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs3(data, bins=50, num_cols=4):\n",
    "\n",
    "    # Plot creation\n",
    "    features = list(data['name'].unique())\n",
    "\n",
    "    #num_rows = int(np.ceil((len(list(features)) - 1) / num_cols)) +1\n",
    "    #fig, ax = plt.subplots(num_rows, num_cols, figsize=(40, 60))\n",
    "    #i= 0\n",
    "    fig, ax = plt.subplots( figsize=(10,10))\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "    for x in tqdm(features, total=len(features), desc=\"Processing...\"):\n",
    "\n",
    "        # Plot  \n",
    "        #row, col = int(i/num_cols), i%num_cols\n",
    "        #print(row, col, i)\n",
    "        #i += 1\n",
    "\n",
    "        # Input to the model\n",
    "        sData = data.loc[data['name'] == x].drop(columns=['name'])[:100000]\n",
    "        sData = torch.from_numpy(\n",
    "            sData.to_numpy(dtype=np.float32)\n",
    "        )\n",
    "\n",
    "        # Pass input through model\n",
    "        _, _, output, _ = model.test_step(sData)\n",
    "\n",
    "        # Calculate the error dist\n",
    "        error_dist = (sData - output)**2\n",
    "        del output, sData\n",
    "        error_dist = error_dist.detach().numpy().sum(axis=1)\n",
    "        #error_dist = error_dist / error_dist.std()\n",
    "\n",
    "        # Define histogram range\n",
    "        hist_min = min(error_dist)\n",
    "        hist_max = max(error_dist)\n",
    "        hist_range = (hist_min, hist_max)\n",
    "\n",
    "        #ax.set_title(x)\n",
    "        \n",
    "        \n",
    "        ax.hist(error_dist, bins=bins, alpha=0.5, label=x, range=hist_range, histtype=u'step')\n",
    "        # ax[row, col].hist(signal[x], bins=bins, alpha=0.5, label=second_name,  range=hist_range)\n",
    "        \n",
    "    ax.autoscale(enable=True) \n",
    "    ax.set_title(\"Error Dist.\")\n",
    "    ax.legend()\n",
    "        \n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs3(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots( figsize=(10,10))\n",
    "for x in tqdm(signal['name'].unique()):\n",
    "    # mu, log_var, x_out, hidden\n",
    "    _, _, x_out, _ = model.test_step(torch.from_numpy(data.loc[data['name'] == x].drop(columns=['name']).to_numpy(dtype=np.float32)))\n",
    "    x_out = x_out.detach().numpy()\n",
    "\n",
    "    if x != 'background.csv':\n",
    "        color = None\n",
    "    else:\n",
    "        color = 'r'\n",
    "    \n",
    "    ax.scatter(hidden[:1000, 0], hidden[:1000, 1], label=x.replace('.csv', ''), alpha=0.5, edgecolors='none', c = color)\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}